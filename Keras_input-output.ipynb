{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Как работаю основные слои"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"S15WD1DnQTPt"},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Concatenate\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, UpSampling2D, Conv2DTranspose\n","from tensorflow.keras.layers import Embedding, Conv1D, LSTM"]},{"cell_type":"markdown","metadata":{"id":"gt4l3wY-UBm-"},"source":["# Основные слои"]},{"cell_type":"markdown","metadata":{"id":"hOyAWHQqb28i"},"source":["### Input и Dense  "]},{"cell_type":"markdown","metadata":{"id":"OFMIJ01GDLl_"},"source":["Слой **Input** инициализирует тензор Keras  \n","\n","Слой **Dense** реализует операцию: output = activation(dot(input, weights) + bias), где:  \n","activation — это функция активации по элементам,  \n","weights — это матрица весов слоя,  \n","bias — это вектор смещения слоя."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-5IhIJwRTZJC"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 64)]              0         \n","                                                                 \n"," dense (Dense)               (None, 200)               13000     \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                2010      \n","                                                                 \n","=================================================================\n","Total params: 15,010\n","Trainable params: 15,010\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(64))\n","x = Dense(200, activation='relu')(inp)\n","x = Dense(10, activation='softmax')(x)\n"," \n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"q4k6HdHf0mtk"},"source":["Слой Dense может работать не только с вектором, но и с матрицей."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"EVMdGrZjR6lC"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 64, 64)]          0         \n","                                                                 \n"," dense_2 (Dense)             (None, 64, 100)           6500      \n","                                                                 \n"," dense_3 (Dense)             (None, 64, 2)             202       \n","                                                                 \n","=================================================================\n","Total params: 6,702\n","Trainable params: 6,702\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(64, 64))\n","x = Dense(100, activation='relu')(inp)\n","x = Dense(2)(x)\n"," \n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1626104973895,"user":{"displayName":"Алексей Тепляков","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9P-6blUqpr0cakI3bzdE42CW9QFnNqQgWLzI0=s64","userId":"13576526196224634555"},"user_tz":-180},"id":"Ob5b_M7FzoDD","outputId":"9d80ae98-2d4d-4dd1-d8cb-fab62cefedea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Размер матрицы выходных данных: (2, 3, 4)\n","Размер матрицы весов: (4, 2)\n"]}],"source":["# входные данные\n","input_data = np.array([[[2,4,6,8],\n","                        [2,4,6,8],\n","                        [2,4,6,8]],\n","                       \n","                       [[3,5,7,9],\n","                        [3,5,7,9],\n","                        [3,5,7,9]]])\n","\n","# Матрица весов: два нейрона с четырьмя весовыми коэффициентами\n","weights = np.array([[0.3, 0.5],\n","                    [0.3, 0.5],\n","                    [0.3, 0.5],\n","                    [0.3, 0.5]])\n","\n","print(\"Размер матрицы выходных данных:\", input_data.shape) \n","print(\"Размер матрицы весов:\", weights.shape)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"AHk2Golt0NpX"},"outputs":[{"data":{"text/plain":["array([[[ 6. , 10. ],\n","        [ 6. , 10. ],\n","        [ 6. , 10. ]],\n","\n","       [[ 7.2, 12. ],\n","        [ 7.2, 12. ],\n","        [ 7.2, 12. ]]])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["output = input_data.dot(weights)  # аналогично input_data @ weights\n","output"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"KDvZAGQL0XQj"},"outputs":[{"name":"stdout","output_type":"stream","text":["Размер выходных данных: (2, 3, 2)\n"]}],"source":["print(\"Размер выходных данных:\", output.shape)"]},{"cell_type":"markdown","metadata":{"id":"wMt0_lwrchvM"},"source":["### Flatten"]},{"cell_type":"markdown","metadata":{"id":"j9Kze8rkBeHW"},"source":["Слой **Flatten** вытягивает данные в вектор. Не трогает размерность, отвечающую за батч."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"-FGn0upOXlVD"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 64, 64)]          0         \n","                                                                 \n"," dense_4 (Dense)             (None, 64, 100)           6500      \n","                                                                 \n"," flatten (Flatten)           (None, 6400)              0         \n","                                                                 \n","=================================================================\n","Total params: 6,500\n","Trainable params: 6,500\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(64,64))\n","x = Dense(100)(inp)\n","x = Flatten()(x)\n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"1Wdkv_9UAW2X"},"source":["### Reshape"]},{"cell_type":"markdown","metadata":{"id":"ltR419WqBxGj"},"source":["Слой **Reshape** приводит тензор к указанной форме."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"kLaKQQCfAWey"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 64, 64)]          0         \n","                                                                 \n"," dense_5 (Dense)             (None, 64, 100)           6500      \n","                                                                 \n"," reshape (Reshape)           (None, 6400)              0         \n","                                                                 \n","=================================================================\n","Total params: 6,500\n","Trainable params: 6,500\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(64,64))\n","x = Dense(100)(inp)\n","x = Reshape((-1,))(x)\n"," \n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"XZ-S1SbVA6ow"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 64)]              0         \n","                                                                 \n"," dense_6 (Dense)             (None, 100)               6500      \n","                                                                 \n"," reshape_1 (Reshape)         (None, 10, 10)            0         \n","                                                                 \n","=================================================================\n","Total params: 6,500\n","Trainable params: 6,500\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(64))\n","x = Dense(100)(inp)\n","x = Reshape((10,10))(x)\n"," \n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"5ZYupvf56Q4B"},"source":["### Concatenate"]},{"cell_type":"markdown","metadata":{"id":"01JaRXLHDQUc"},"source":["Слой **Concatenate** объединяет данные с разных ветвей нейронной сети."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"8YSGajrWyWEk"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_5\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_6 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n","                                                                                                  \n"," input_7 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 64, 64, 6)    0           ['input_6[0][0]',                \n","                                                                  'input_7[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 0\n","Trainable params: 0\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["inp_1 = Input(shape=(64, 64, 3))\n","inp_2 = Input(shape=(64, 64, 3))\n","x = Concatenate(axis=3)([inp_1, inp_2])\n"," \n","model = Model([inp_1, inp_2], x)\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"SKHjfN0HUGzC"},"source":["# Сверточные слои"]},{"cell_type":"markdown","metadata":{"id":"sBgLRZPeIQHZ"},"source":["### Conv2D"]},{"cell_type":"markdown","metadata":{"id":"gxk1ReloIWFp"},"source":["Слой **Conv2D** создает ядро свертки, которое свертывается со входом слоя для получения выходного тензора (пример - свертка изображений).\n","\n","Входной слой должен иметь три размерности (не считая размерности для батча)  \n","\n","Основные параметры слоя, влияющие на размер выходного тензора:  \n","- *filters* - количество нейронов в сверточном слое  \n","- *kernel_size* - размеры ядра свертки  \n","- *padding* - позволяет сохранить размерность массива по высоте и ширине не зависимо от размера ядра свертки \n","- *strides* - шаги свертки по высоте и ширине  \n","- *dilation_rate* - параметр для задания разреженной свертки    \n","  \n","  \n","*Формула расчета выходной размерности:*  \n","https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"P1Bne2FbTz7i"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_8 (InputLayer)        [(None, 128, 128, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 126, 126, 32)      896       \n","                                                                 \n","=================================================================\n","Total params: 896\n","Trainable params: 896\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(128, 128, 3))\n","x = Conv2D(filters=32, kernel_size=(3,3))(inp)\n"," \n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"jnGrgkAfwa2L"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_9 (InputLayer)        [(None, 128, 128, 3)]     0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 128, 128, 32)      896       \n","                                                                 \n","=================================================================\n","Total params: 896\n","Trainable params: 896\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(128, 128, 3))\n","x = Conv2D(filters=32, kernel_size=(3,3), padding='same')(inp)\n"," \n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"gR7U_UvXwxos"},"source":["Добавим параметр strides."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"geWE_HRdwvNa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_10 (InputLayer)       [(None, 128, 128, 3)]     0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 64, 64, 32)        896       \n","                                                                 \n","=================================================================\n","Total params: 896\n","Trainable params: 896\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(128, 128, 3))\n","x = Conv2D(filters=32, kernel_size=(3,3), padding='same', strides=(2,2))(inp)\n"," \n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"ZwaoF9V1yHR5"},"source":["Добавим параметр dilation_rate."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"qLelH1X4xfRO"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_11 (InputLayer)       [(None, 128, 128, 3)]     0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 124, 124, 32)      896       \n","                                                                 \n","=================================================================\n","Total params: 896\n","Trainable params: 896\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(128, 128, 3))\n","x = Conv2D(filters=32, kernel_size=(3,3), padding='valid', dilation_rate=(2,2))(inp)\n"," \n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"eAdL_XQZK1K-"},"source":["### MaxPool2D"]},{"cell_type":"markdown","metadata":{"id":"GdOEHFCvK40I"},"source":["Слой **MaxPool2D** уменьшает размер входных данных по высоте и ширине, принимая максимальное значение в окне для каждого канала. Размер окна определяется параметром *pool_size*.\n","\n","Также есть параметр *strides*, который работает так же как и в свертке, но по умолчанию равен размеру окна (pool_size).  \n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"PZDZb8NMUJWW"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_12 (InputLayer)       [(None, 128, 128, 3)]     0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 128, 128, 32)      896       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n"," )                                                               \n","                                                                 \n","=================================================================\n","Total params: 896\n","Trainable params: 896\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(128, 128, 3))\n","x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(inp)\n","x = MaxPool2D(pool_size=2)(x)\n"," \n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"wVaMZW-o3BUX"},"source":["Если размеры высоты/ширины не делятся нацело на размер окна, то деление происходит с округлением вниз."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"qw3Ikl4S3Amy"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_11\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_13 (InputLayer)       [(None, 127, 127, 3)]     0         \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 127, 127, 32)      896       \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 63, 63, 32)       0         \n"," 2D)                                                             \n","                                                                 \n","=================================================================\n","Total params: 896\n","Trainable params: 896\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(127, 127, 3))\n","x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(inp)\n","x = MaxPool2D(pool_size=2)(x)\n"," \n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"NzKD_NWC4lLG"},"source":["Однако, это можно изменить, если сделать заполнение через *Padding*. "]},{"cell_type":"code","execution_count":17,"metadata":{"id":"5tFjs5e14kSB"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_12\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_14 (InputLayer)       [(None, 127, 127, 3)]     0         \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 127, 127, 32)      896       \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 64, 64, 32)       0         \n"," 2D)                                                             \n","                                                                 \n","=================================================================\n","Total params: 896\n","Trainable params: 896\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(127, 127, 3))\n","x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(inp)\n","x = MaxPool2D(pool_size=2, padding='same')(x)\n"," \n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"LLFkhuKi6A8G"},"source":["### UpSampling2D"]},{"cell_type":"markdown","metadata":{"id":"XKfKzFmB6D0U"},"source":["Слой **UpSampling2D** увеличивает размер тензора, путем повторения данных."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"OYd6LqrH6EHp"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_13\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_15 (InputLayer)       [(None, 128, 128, 3)]     0         \n","                                                                 \n"," up_sampling2d (UpSampling2D  (None, 256, 256, 3)      0         \n"," )                                                               \n","                                                                 \n","=================================================================\n","Total params: 0\n","Trainable params: 0\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(128, 128, 3))\n","x = UpSampling2D(size=(2, 2))(inp)\n"," \n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"HgVrBrCj96R0"},"source":["Пример работы слоя."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"fk5kRSGq8-S1"},"outputs":[],"source":["inp = Input(shape=(2, 2, 1))\n","x = UpSampling2D(size=(2, 2))(inp)\n"," \n","model = Model(inp, x)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"KJ2ky-ZU9HKj"},"outputs":[{"data":{"text/plain":["array([[4, 2],\n","       [3, 6]])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Создаем данные\n","data = np.array([[4, 2],\n","\t\t\t     [3, 6]])\n","data"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"kNZDNzGt9S1r"},"outputs":[],"source":["# Модель принимает на вход данные размерности 4D, поэтому приводим к нужному размеру\n","data = data.reshape((1, 2, 2, 1))"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"Y-EjyZGQ9YPY"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 288ms/step\n"]},{"data":{"text/plain":["array([[4., 4., 2., 2.],\n","       [4., 4., 2., 2.],\n","       [3., 3., 6., 6.],\n","       [3., 3., 6., 6.]], dtype=float32)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Подаем данные в модель и возвращаем делаем обратный reshape\n","pred = model.predict(data)\n","pred.reshape((4, 4))"]},{"cell_type":"markdown","metadata":{"id":"wEo5eW7YBnr2"},"source":["### Conv2DTranspose"]},{"cell_type":"markdown","metadata":{"id":"su6U5LOGBqTw"},"source":["Слой **Conv2DTranspose** также увеличивает размер тензора, но с использованием сверток. Его еще называют Deconvolution-слой.\n","\n","Он увеличивает размер изображения по высоте и ширине аналогично слою UpSampling2D (только заполняя нулями), а затем применяет свертку к полученному массиву.\n","\n","Параметр *strides* здесь отвечает за то насколько сильно расширяется исходный массив."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"DzWCyME2CX1_"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_15\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_17 (InputLayer)       [(None, 128, 128, 3)]     0         \n","                                                                 \n"," conv2d_transpose (Conv2DTra  (None, 256, 256, 32)     896       \n"," nspose)                                                         \n","                                                                 \n","=================================================================\n","Total params: 896\n","Trainable params: 896\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(128, 128, 3))\n","x = Conv2DTranspose(filters=32, kernel_size=(3, 3), strides=(2, 2), padding='same')(inp)\n"," \n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"aQ2D4TFzEAd5"},"source":["Пример работы слоя."]},{"cell_type":"code","execution_count":45,"metadata":{"id":"LPhmG0P3D_pv"},"outputs":[],"source":["inp = Input(shape=(2, 2, 1))\n","x = Conv2DTranspose(filters=1, kernel_size=(1, 1), strides=(3, 3), padding='same')(inp)\n"," \n","model = Model(inp, x)"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"VOUQBciIBn4s"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[4 2]\n"," [3 6]]\n"]}],"source":["# Создаем данные\n","data = np.array([[4, 2],\n","\t\t\t     [3, 6]])\n","print(data)\n","\n","# Модель принимает на вход данные размерности 4D, поэтому приводим к нужному размеру\n","data = data.reshape((1, 2, 2, 1))"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"MwILXRhyEQE3"},"outputs":[],"source":["# Для демонстрации установим в модель веса, который никак не влияют на выходные данные\n","weights = [np.array([[[[1]]]]), np.array([0])]\n","model.set_weights(weights)\n"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"WUAunj1RD0mQ"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 57ms/step\n"]},{"data":{"text/plain":["array([[4., 0., 0., 2., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [3., 0., 0., 6., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.]], dtype=float32)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# Подаем данные в модель и возвращаем делаем обратный reshape\n","pred = model.predict(data)\n","pred.reshape((6, 6))"]},{"cell_type":"markdown","metadata":{"id":"jWepqZm4VYDj"},"source":["# Слои для работы с последовательностями"]},{"cell_type":"markdown","metadata":{"id":"3Xu86sE9Gdap"},"source":["### Embedding"]},{"cell_type":"markdown","metadata":{"id":"pePJ4thOGgUi"},"source":["Слой **Embedding** создает векторное представление каждого элемента последовательности.\n","\n","- *input_dim* - размер словаря\n","- *output_dim* - размерность векторного пространства"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"fsogCOdGValE"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_17\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_19 (InputLayer)       [(None, 10)]              0         \n","                                                                 \n"," embedding (Embedding)       (None, 10, 5)             5000      \n","                                                                 \n","=================================================================\n","Total params: 5,000\n","Trainable params: 5,000\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(10))\n","x = Embedding(input_dim=1000, output_dim=5)(inp)\n"," \n","model = Model(inp, x)\n"," \n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"w384GMC0LOrG"},"source":["Пример использования."]},{"cell_type":"code","execution_count":29,"metadata":{"id":"bMsQ3IeKK4Fk"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='input_19'), name='input_19', description=\"created by layer 'input_19'\"), but it was called on an input with incompatible shape (None,).\n","1/1 [==============================] - 0s 42ms/step\n","[[ 0.00193129 -0.00854864 -0.03672947  0.04313781  0.0271039 ]\n"," [ 0.04726781  0.03637854  0.02126632  0.02061016 -0.01318913]\n"," [-0.03973256  0.04299212  0.0466626  -0.04153728 -0.01947212]\n"," [ 0.01582838 -0.01938022 -0.00184568  0.0451187  -0.03858887]\n"," [ 0.01100177 -0.03717066 -0.04971293 -0.00764813  0.02925721]\n"," [ 0.00985394 -0.0401486   0.02489301  0.02698697 -0.00691744]\n"," [ 0.01207183  0.02267965 -0.00673886 -0.00702526 -0.00835854]\n"," [ 0.01037439 -0.04707965  0.03109381  0.03826543 -0.04105661]\n"," [-0.02557571 -0.00451971 -0.01754279  0.0238851   0.00831141]\n"," [-0.0261048  -0.03440655  0.02476935 -0.01002254 -0.04727645]]\n"]}],"source":["data = np.arange(10)\n","pred = model.predict(data)\n","print(pred)"]},{"cell_type":"markdown","metadata":{"id":"eKubm7InJ1g2"},"source":["### Conv1D"]},{"cell_type":"markdown","metadata":{"id":"9lK8sEYqLmZf"},"source":["Слой **Conv1D** аналогичен слою Conv2D, но работает с данными меньшей размерности."]},{"cell_type":"code","execution_count":30,"metadata":{"id":"w14FERndhgDL"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_18\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_20 (InputLayer)       [(None, 100)]             0         \n","                                                                 \n"," embedding_1 (Embedding)     (None, 100, 20)           20000     \n","                                                                 \n"," conv1d (Conv1D)             (None, 100, 32)           3232      \n","                                                                 \n","=================================================================\n","Total params: 23,232\n","Trainable params: 23,232\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(100))\n","x = Embedding(input_dim=1000, output_dim=20)(inp)\n","x = Conv1D(filters=32, kernel_size=(5), padding='same')(x)\n"," \n","model = Model(inp, x)\n"," \n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"X4MruX9-J9dq"},"source":["### LSTM"]},{"cell_type":"markdown","metadata":{"id":"tJ4G1OLjPviX"},"source":["<figure>\n","<center>\n","<img src='https://hsto.org/web/67b/04f/73b/67b04f73b4c34ba38edfa207e09de07c.png' />\n","<figcaption>LSTM</figcaption></center>\n","</figure>"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"b1uFgtoikUXs"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_19\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_21 (InputLayer)       [(None, 100)]             0         \n","                                                                 \n"," embedding_2 (Embedding)     (None, 100, 20)           20000     \n","                                                                 \n"," lstm (LSTM)                 (None, 64)                21760     \n","                                                                 \n","=================================================================\n","Total params: 41,760\n","Trainable params: 41,760\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(100))\n","x = Embedding(input_dim=1000, output_dim=20)(inp)\n","x = LSTM(units=64)(x)\n"," \n","model = Model(inp, x)\n"," \n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"WV9g34ayTQva"},"source":["*return_sequences* - отвечает за то возвращается ли только последний вывод последовательности или вся последовательность."]},{"cell_type":"code","execution_count":32,"metadata":{"id":"ZY4RfrRcWOOm"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 484ms/step\n"]},{"data":{"text/plain":["array([[[-0.00969294],\n","        [-0.0264568 ],\n","        [-0.04812365],\n","        [-0.0728191 ]]], dtype=float32)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["inp = Input(shape=(4, 1))\n","x = LSTM(units=1, return_sequences=True)(inp)\n","model = Model(inp, x)\n","\n","# Входные данные\n","data = np.array([0.1, 0.2, 0.3, 0.4]).reshape((1,4,1))\n","\n","model.predict(data)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"bxlYQkc0Mxcn"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_21\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_23 (InputLayer)       [(None, 10)]              0         \n","                                                                 \n"," embedding_3 (Embedding)     (None, 10, 20)            20000     \n","                                                                 \n"," lstm_2 (LSTM)               (None, 10, 64)            21760     \n","                                                                 \n","=================================================================\n","Total params: 41,760\n","Trainable params: 41,760\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(10))\n","x = Embedding(input_dim=1000, output_dim=20)(inp)\n","x = LSTM(units=64, return_sequences=True)(x)\n","\n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"G-L7Z4VMT6S4"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FBC47BF490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 1s 610ms/step\n"]},{"data":{"text/plain":["(1, 10, 64)"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["data = np.arange(10).reshape(1,10)\n","model.predict(data).shape"]},{"cell_type":"markdown","metadata":{"id":"5ea239oZSPqI"},"source":["*return_state* - в дополнение к выходным данным возвращает состояние ячейки.  \n","\n","В итоге возвращается три массива:  \n","1. Скрытое состояние LSTM для последнего временного шага.\n","2. Скрытое состояние LSTM для последнего временного шага (еще раз).\n","3. Состояние ячейки LSTM для последнего временного шага.\n","\n","Скрытое состояние и состояние ячейки можно использовать для инициализации состояний другого слоя LSTM с тем же количеством ячеек."]},{"cell_type":"code","execution_count":35,"metadata":{"id":"uyMqSfgFXIzj"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FBCA980DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 1s 727ms/step\n"]},{"data":{"text/plain":["[array([[-0.09313004]], dtype=float32),\n"," array([[-0.09313004]], dtype=float32),\n"," array([[-0.20073888]], dtype=float32)]"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["inp = Input(shape=(4, 1))\n","lstm1, state_h, state_c = LSTM(units=1, return_state=True)(inp)\n","model = Model(inputs=inp, outputs=[lstm1, state_h, state_c])\n","\n","# Входыне данные\n","data = np.array([0.1, 0.2, 0.3, 0.4]).reshape((1,4,1))\n","\n","model.predict(data)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"tvRO9AXMs5qX"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_23\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_25 (InputLayer)       [(None, 10)]              0         \n","                                                                 \n"," embedding_4 (Embedding)     (None, 10, 20)            20000     \n","                                                                 \n"," lstm_4 (LSTM)               [(None, 64),              21760     \n","                              (None, 64),                        \n","                              (None, 64)]                        \n","                                                                 \n","=================================================================\n","Total params: 41,760\n","Trainable params: 41,760\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(10))\n","x = Embedding(input_dim=1000, output_dim=20)(inp)\n","x = LSTM(units=64, return_state=True)(x)\n"," \n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"nmL8pQdqReUH"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 466ms/step\n","3\n","(1, 64) (1, 64) (1, 64)\n"]}],"source":["data = np.arange(10).reshape(1,10)\n","pred = model.predict(data)\n","print(len(pred))\n","print(pred[0].shape, pred[1].shape, pred[2].shape)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"VmA43WaxXHO7"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 370ms/step\n"]},{"data":{"text/plain":["[array([[-0.12626255]], dtype=float32),\n"," array([[-0.12626255]], dtype=float32),\n"," array([[-0.2661676]], dtype=float32)]"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["inp = Input(shape=(4, 1))\n","lstm1, state_h, state_c = LSTM(units=1, return_state=True)(inp)\n","model = Model(inputs=inp, outputs=[lstm1, state_h, state_c])\n","\n","# Входыне данные\n","data = np.array([0.1, 0.2, 0.3, 0.4]).reshape((1,4,1))\n","\n","model.predict(data)"]},{"cell_type":"markdown","metadata":{"id":"xpqucHhRZx4w"},"source":["return_state + return_sequences"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"VAsRhRx6Z3RP"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 539ms/step\n"]},{"data":{"text/plain":["[array([[[-0.01553788],\n","         [-0.03938013],\n","         [-0.06631017],\n","         [-0.09259953]]], dtype=float32),\n"," array([[-0.09259953]], dtype=float32),\n"," array([[-0.23518857]], dtype=float32)]"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["inp = Input(shape=(4, 1))\n","lstm1, state_h, state_c = LSTM(units=1, return_sequences=True, return_state=True)(inp)\n","model = Model(inputs=inp, outputs=[lstm1, state_h, state_c])\n","\n","# Входыне данные\n","data = np.array([0.1, 0.2, 0.3, 0.4]).reshape((1,4,1))\n","\n","model.predict(data)"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"7PSWUJVwOAOs"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_26\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_28 (InputLayer)       [(None, 10)]              0         \n","                                                                 \n"," embedding_5 (Embedding)     (None, 10, 20)            20000     \n","                                                                 \n"," lstm_7 (LSTM)               [(None, 10, 64),          21760     \n","                              (None, 64),                        \n","                              (None, 64)]                        \n","                                                                 \n","=================================================================\n","Total params: 41,760\n","Trainable params: 41,760\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inp = Input(shape=(10))\n","x = Embedding(input_dim=1000, output_dim=20)(inp)\n","x = LSTM(64, return_state=True, return_sequences=True, activation='softmax') (x)\n"," \n","model = Model(inp, x)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"0mjR3VpOUWhk"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 250ms/step\n","3\n","(1, 10, 64) (1, 64) (1, 64)\n"]}],"source":["data = np.arange(10).reshape(1,10)\n","pred = model.predict(data)\n","print(len(pred))\n","print(pred[0].shape, pred[1].shape, pred[2].shape)"]}],"metadata":{"colab":{"collapsed_sections":["gt4l3wY-UBm-","SKHjfN0HUGzC","jWepqZm4VYDj"],"name":"УИИ \"Размеры выходных данных слоев в Keras.ipynb\"","provenance":[{"file_id":"1vPmLLFCd-6DE5Ie3wL9PsjNQ5HNIlVjF","timestamp":1626167255343}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"}}},"nbformat":4,"nbformat_minor":0}
